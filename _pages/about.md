---
permalink: / 
layout: archive
title: "Homepage"
author_profile: true
redirect_from:
  - /about/
  - /about.html
---

**"Think big, act small, and move fast"**

This webpage is last updated on **2024/10/15**.

Để xem phiên bản tiếng Việt của trang này, vui lòng kéo xuống dưới hoặc nhấn vào [đây](https://dovanquyet.github.io/#trang-chủ-phiên-bản-tiếng-việt-cho-trang-này)

<!-- > I am open to supervising UG students who are academically strong, highly motivated, and having a decent AI-coding skill (Python, Pytorch, and Huggingface Transformers are preferred). If you are interested in NLP and want to collaborate with me, feel free to contact and send your CV + Unofficial Transcript to me via email.  -->

## About me

Hi folks, welcome to my personal homepage! You can call me by my real name Quyet (pronounce like 'Quest'), or my English name William. I'm a first-year PhD student at Virginia Tech where I work with [Prof. Tu Vu](https://tuvllms.github.io/). Previously, I got my M.Phil in Computer Science and B.Sc in Data Science and Pure Math (Advanced Track) from HKUST in Sep 2024 and July 2022. During my MPhil program, I was fortunate to be supervised by [Prof. Yangqiu Song](https://www.cse.ust.hk/~yqsong/).

**My primary research interests are centered around AI/NLP** (Artificial Intelligence / Natural Language Processing). Although the field drastically progresses in the last decade, I do not expect language models (as the "main products" of the field) to really understand human language nor expose super-human capability. Instead, I expect them to mimic human behaviors (either as an individual or a group of people) as realistic as possible and benefit industrial applications.

I aspire to develop artificial intelligence (AI) in a similar way as human intelligence develops. In the era of large AI models, my research focus includes:

1. **Instruction following capability**: At this moment, State-of-The-Art LLMs can perform well on multiple tasks with simple instructions. But what if the task and instructions are more realistic and complex? Can LLMs follow all the instructions? That is what I am working on.
1. **Model merging**: It is very impactful if we can merge models (of difference size, different pretraining procedure) so that we can transfer strengths and minimize weaknesses of models in the merged model.
1. **AI for Math**: As an IMO medalist, I am interested in developing AI math-reasoning systems based on my math-solving techniques.
1. **Neuro-symbolic reasoning system**: Learning both system-1 and sytem-2 reasoning capability in an efficient way and within a model by combining neural and symbolic modules.
<!-- 1. Neuro-symbolic reasoning methods: I intend to investigate the utilization of external resources, specifically existing knowledge graphs, in order to facilitate the identification and rectification of erroneous beliefs within language models. "RECKONING" and "Language Models with Rationality" -->
<!-- 1. Efficient (transfer) learning: I aspire to enable LMs to learn from very little supervision, which is a hallmark of human intelligence. I am particularly interested in how to discover and effectively finetune the most critical subnetworks of LMs w.r.t to each task. RS_Tu.pdf and "Discovering Knowledge-Critical Subnetworks in Pretrained Language Models" -->
<!-- 1. Basic learning ability: How to train and evaluate LLMs on such crucial skills (rule following (shift of distribution), new skill (soft rule)) -->

About my personal life, I am a big fan of music. I consider myself as an amateur singer. Check this [Youtube channel](https://www.youtube.com/channel/UCw0K4xQPwp8wZp6rkWRcTCg) to hear my voice :D Besides, about my spiritual, I am hugely inspired by the [Zen Master Thich Nhat Hanh](https://plumvillage.org/thich-nhat-hanh/). His Buddhism accounts for the major portion of my reasoning system. My favorite book, not surprisingly, is one of his books, Old Path White Cloud ([en](https://terebess.hu/zen/mesterek/Thich%20Nhat%20Hanh%20-%20Old%20Path%20White%20Clouds.pdf),[vi](https://thuvienhoasen.org/images/file/3GfDvp1G0QgQAHtP/duong-xua-may-trang.pdf)). Also, from Feb 2023 to April 2024, I served as the Head of Event Organization of [Vietnamese Students' Association in HK](https://www.facebook.com/profile.php?id=100087606602683).

My full academic profile can be found [here](https://dovanquyet.github.io/academic). For (interesting) stories about my personal life, please check [here](https://dovanquyet.github.io/posts/vi/chuyen-hang-ngay).


## Academic News

- [2024/08] Start my PhD journey at Virginia Tech under the supervision of Prof. Tu Vu
- [2024/03] Decide to do my PhD at Virginia Tech!
- [2024/01] My first first-author [paper](https://arxiv.org/abs/2401.14003) has been accepted to EACL'24!
- [2024/01] Finished my PhD application. I got 6 interviews from 4 universities :D But probably no more :/ Updated: two more interviews, one is from a university that I haven't applied :D And later one more interview invitation but I declined due my crazily heavy workload :/
- [2023/05] Our paper on Contextualized Commonsense Causal Reasoning has been accepted to ACL'23 Main Conference. Check it [here](https://arxiv.org/abs/2305.05191)
- [2023/04] Our paper on Commonsense Knowledge Base Population is archived. Check it [here](https://arxiv.org/abs/2304.10392)
- [2023/02] Our work on evaluating ChatGPT is out. Check this [paper](https://arxiv.org/abs/2302.04023). Updated: it is accepted to AACL 2023 (Poster).
- [2022/11] Have a chat with Prof. Pascale. She is also interested in using commonsense knowledge to control the language model's generation and support open-ended QA. Thus, I start working with her students :P. Updated: I am no longer a part of that group since July 2023. I feel in debt that I learned a lot from all people in the lab but only contributed a little :/
- [2022/10] My [first paper](https://arxiv.org/abs/2210.07988) has been accepted as Findings of EMNLP2022. Yeah!!!
- [2022/06] My first paper has been submitted to EMNLP2022. Let's see if it's accepted =)
- [2022/05] My application for M.Phil program to HKUST is accepted. I will remain in HK for two more years.


## Contact me!

Feel free to reach me at william (dot) vqdo {at} vt [dot] edu.


## Trang Chủ (phiên bản tiếng Việt cho trang này)

Chào mừng mọi người đến mới trang chủ của mình. Hiện tại mình đang là nghiên cứu sinh năm nhất của chương trình Tiến Sĩ ở Đại học Bách Khoa bang Virginia (Virginia Tech) với sự hướng dẫn của Giáo sư [Vũ Thanh Tú](https://tuvllms.github.io/). Trước đó, mình nhận bằng Thạc sĩ Nghiên cứu (MPhil) ngành Computer Science (Khoa học Máy tính) và Cử nhân ngành Data Science (Khoa học Dữ liệu) và Advanced Pure Math (Toán thuần túy nâng cao) từ trường ở [Hong Kong University of Science and Technology](https://hkust.edu.hk/) vào tháng 9 năm 2024 và tháng 7 năm 2022. Trong thời gian học Thạc sĩ, mình may mắn được làm việc với Giáo sư [Yangqiu Song (Tống Dương Thu)](https://www.cse.ust.hk/~yqsong/).

Nghiên cứu của mình tập trung vào ngành NLP (Xử lý Ngôn ngữ tự nhiên), cụ thể là LLMs (Mô hình ngôn ngữ lớn). Về cuộc sống, mình rất thích âm nhạc. Giọng hát mình khá ổn và đã đi trình diễn ở một số nơi. Nhấn vào [kênh Youtube này](https://www.youtube.com/channel/UCw0K4xQPwp8wZp6rkWRcTCg) để nghe một vài bài hát mình cover hoặc tự viết :D Về tinh thần, lối suy nghĩ của mình được ảnh hưởng lớn từ [Thiền sư Thích Nhất Hạnh](https://plumvillage.org/thich-nhat-hanh/), đặc biệt là qua cuốn sách Đường Xưa Mây Trắng ([en](https://terebess.hu/zen/mesterek/Thich%20Nhat%20Hanh%20-%20Old%20Path%20White%20Clouds.pdf),[vi](https://thuvienhoasen.org/images/file/3GfDvp1G0QgQAHtP/duong-xua-may-trang.pdf)). Bên cạnh đó, từ tháng 02/2023 đến tháng 04/2024, mình tham gia Ban cán sự của [Hội sinh viên VN tại HK](https://www.facebook.com/profile.php?id=100087606602683) với vai trò Trưởng ban tổ chức sự kiện.

Cuối cùng, bạn có thể xem những thông tin liên quan đến học thuật của mình tại [đây](https://dovanquyet.github.io/academic), và những bài viết blog liên quan đến cuộc sống hàng ngày tại [đây](https://dovanquyet.github.io/posts/vi/chuyen-hang-ngay).

